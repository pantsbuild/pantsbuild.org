---
title: python
---

import Option from "@site/src/components/reference/Option";
import styles from "@site/src/components/reference/styles.module.css";

---

Options for Pants&#x27;s Python backend.

Backend: <span className="color--primary">`pants.core`</span>

Config section: <span className="color--primary">`[python]`</span>

<span className={styles.options}>

## Basic options

### `macos_big_sur_compatibility`

<Option
  cli_repr={`--[no-]python-macos-big-sur-compatibility`}
  env_repr='PANTS_PYTHON_MACOS_BIG_SUR_COMPATIBILITY'
  default_repr={`False`}
>

If set, and if running on MacOS Big Sur, use macosx_10_16 as the platform when building wheels. Otherwise, the default of macosx_11_0 will be used. This may be required for pip to be able to install the resulting distribution on Big Sur.

</Option>

## Advanced options

### `interpreter_constraints`

<Option
  cli_repr={`--python-interpreter-constraints="[<requirement>, <requirement>, ...]"`}
  env_repr='PANTS_PYTHON_INTERPRETER_CONSTRAINTS'
  default_repr={`["CPython>=3.6,<4"]`}
>

The Python interpreters your codebase is compatible with.

Specify with requirement syntax, e.g. &#x27;CPython&gt;=2.7,&lt;3&#x27; (A CPython interpreter with version &gt;=2.7 AND version &lt;3) or &#x27;PyPy&#x27; (A pypy interpreter of any version). Multiple constraint strings will be ORed together.

These constraints are used as the default value for the `interpreter_constraints` field of Python targets.

</Option>

### `interpreter_versions_universe`

<Option
  cli_repr={`--python-interpreter-versions-universe="['<str>', '<str>', ...]"`}
  env_repr='PANTS_PYTHON_INTERPRETER_VERSIONS_UNIVERSE'
  default_repr={`[\n  "2.7",\n  "3.5",\n  "3.6",\n  "3.7",\n  "3.8",\n  "3.9",\n  "3.10"\n]`}
>

All known Python major/minor interpreter versions that may be used by either your code or tools used by your code.

This is used by Pants to robustly handle interpreter constraints, such as knowing when generating lockfiles which Python versions to check if your code is using.

This does not control which interpreter your code will use. Instead, to set your interpreter constraints, update `[python].interpreter_constraints`, the `interpreter_constraints` field, and relevant tool options like `[isort].interpreter_constraints` to tell Pants which interpreters your code actually uses. See https://www.pantsbuild.org/v2.10/docs/python-interpreter-compatibility.

All elements must be the minor and major Python version, e.g. &#x27;2.7&#x27; or &#x27;3.10&#x27;. Do not include the patch version.

</Option>

### `requirement_constraints`

<Option
  cli_repr={`--python-requirement-constraints=<file_option>`}
  env_repr='PANTS_PYTHON_REQUIREMENT_CONSTRAINTS'
  default_repr={`None`}
>

When resolving third-party requirements for your own code (vs. tools you run), use this constraints file to determine which versions to use.

Mutually exclusive with `[python].enable_resolves`, which we generally recommend as an improvement over constraints file, including due to less supply chain risk thanks to `--hash` support.

See https://pip.pypa.io/en/stable/user_guide/#constraints-files for more information on the format of constraint files and how constraints are applied in Pex and pip.

The constraints only apply when resolving user requirements, rather than tools you run like Black and Pytest. To constrain tools, set `[tool].lockfile`, e.g. `[black].lockfile`.

</Option>

### `resolve_all_constraints`

<Option
  cli_repr={`--[no-]python-resolve-all-constraints`}
  env_repr='PANTS_PYTHON_RESOLVE_ALL_CONSTRAINTS'
  default_repr={`True`}
>

(Only relevant when using`[python].requirement_constraints`.) If enabled, when resolving requirements, Pants will first resolve your entire constraints file as a single global resolve. Then, if the code uses a subset of your constraints file, Pants will extract the relevant requirements from that global resolve so that only what&#x27;s actually needed gets used. If disabled, Pants will not use a global resolve and will resolve each subset of your requirements independently.

Usually this option should be enabled because it can result in far fewer resolves.

</Option>

### `enable_resolves`

<Option
  cli_repr={`--[no-]python-enable-resolves`}
  env_repr='PANTS_PYTHON_ENABLE_RESOLVES'
  default_repr={`False`}
>

Set to true to enable the lockfile and multiple resolves mechanisms. See `[python].resolves` and https://www.pantsbuild.org/v2.10/docs/python-third-party-dependencies an explanation of this feature.

Warning: you may have issues with generating valid lockfiles via the `generate-lockfiles` goal and may need to instead manually generate the locks, e.g. by running `pip freeze`. Categorically, the lockfile cannot be generated by Pants if you need to use VCS (Git) requirements and local requirements, along with `[python-repos]` for custom indexes/cheeseshops. See https://www.pantsbuild.org/v2.10/docs/python-third-party-dependencies for more details on how to manually generate lockfiles.

Several users have also had issues with how Poetry&#x27;s lockfile generation handles environment markers for transitive dependencies; certain dependencies end up with nonsensical environment markers which cause the dependency to not be installed, then for Pants/Pex to complain the dependency is missing, even though it&#x27;s in the lockfile. The workaround is to manually create a `python_requirement` target for the problematic transitive dependencies so that they are seen as direct requirements, rather than transitive, then to regenerate the lockfile with `generate-lockfiles`.

We are working to fix these issues by using PEX &amp; pip to generate the lockfile.

Outside of the above issues with lockfile generation, we believe this feature is stable. It offers three major benefits compared to `[python].requirement_constraints`:

1. Uses `--hash` to validate that all downloaded files are expected, which reduces the risk of supply chain attacks.
2. Enforces that all transitive dependencies are in the lockfile, whereas constraints allow you to leave off dependencies. This ensures your build is more stable and reduces the risk of supply chain attacks.
3. Allows you to have multiple resolves in your repository.

Mutually exclusive with `[python].requirement_constraints`.

</Option>

### `resolves`

<Option
  cli_repr={`--python-resolves="{'key1': val1, 'key2': val2, ...}"`}
  env_repr='PANTS_PYTHON_RESOLVES'
  default_repr={`{"python-default": "3rdparty/python/default.lock"}`}
>

A mapping of logical names to lockfile paths used in your project.

Many organizations only need a single resolve for their whole project, which is a good default and the simplest thing to do. However, you may need multiple resolves, such as if you use two conflicting versions of a requirement in your repository.

If you only need a single resolve, run `./pants generate-lockfiles` to generate the lockfile.

If you need multiple resolves:

1. Via this option, define multiple resolve names and their lockfile paths. The names should be meaningful to your repository, such as `data-science` or `pants-plugins`.
2. Set the default with `[python].default_resolve`.
3. Update your `python_requirement` targets with the `resolve` field to declare which resolve they should be available in. They default to `[python].default_resolve`, so you only need to update targets that you want in non-default resolves. (Often you&#x27;ll set this via the `python_requirements` or `poetry_requirements` target generators)
4. Run `./pants generate-lockfiles` to generate the lockfiles. If the results aren&#x27;t what you&#x27;d expect, adjust the prior step.
5. Update any targets like `python_source` / `python_sources`, `python_test` / `python_tests`, and `pex_binary` which need to set a non-default resolve with the `resolve` field.

If a target can work with multiple resolves, create a distinct target per resolve. This will be made more ergonomic in an upcoming Pants release through a new `parametrize` feature.

You can name the lockfile paths what you would like; Pants does not expect a certain file extension or location.

Only applies if `[python].enable_resolves` is true.

</Option>

### `default_resolve`

<Option
  cli_repr={`--python-default-resolve=<str>`}
  env_repr='PANTS_PYTHON_DEFAULT_RESOLVE'
  default_repr={`python-default`}
>

The default value used for the `resolve` field.

The name must be defined as a resolve in `[python].resolves`.

</Option>

### `resolves_to_interpreter_constraints`

<Option
  cli_repr={`--python-resolves-to-interpreter-constraints="{'key1': val1, 'key2': val2, ...}"`}
  env_repr='PANTS_PYTHON_RESOLVES_TO_INTERPRETER_CONSTRAINTS'
  default_repr={`{}`}
>

Override the interpreter constraints to use when generating a resolve&#x27;s lockfile with the `generate-lockfiles` goal.

By default, each resolve from `[python].resolves` will use your global interpreter constraints set in `[python].interpreter_constraints`. With this option, you can override each resolve to use certain interpreter constraints, such as `{'data-science': ['==3.8.*']}`.

Pants will validate that the interpreter constraints of your code using a resolve are compatible with that resolve&#x27;s own constraints. For example, if your code is set to use [&#x27;==3.9.*&#x27;] via the `interpreter_constraints` field, but it&#x27;s also using a resolve whose interpreter constraints are set to [&#x27;==3.7.*&#x27;], then Pants will error explaining the incompatibility.

The keys must be defined as resolves in `[python].resolves`.

</Option>

### `invalid_lockfile_behavior`

<Option
  cli_repr={`--python-invalid-lockfile-behavior=<InvalidLockfileBehavior>`}
  env_repr='PANTS_PYTHON_INVALID_LOCKFILE_BEHAVIOR'
  one_of='error, ignore, warn'
  default_repr={`error`}
>

The behavior when a lockfile has requirements or interpreter constraints that are not compatible with what the current build is using.

We recommend keeping the default of `error` for CI builds.

</Option>

### `resolves_generate_lockfiles`

<Option
  cli_repr={`--[no-]python-resolves-generate-lockfiles`}
  env_repr='PANTS_PYTHON_RESOLVES_GENERATE_LOCKFILES'
  default_repr={`True`}
>

If False, Pants will not attempt to generate lockfiles for `[python].resolves` when running the `generate-lockfiles` goal.

This is intended to allow you to manually generate lockfiles as a workaround for the issues described at https://www.pantsbuild.org/v2.10/docs/python-third-party-dependencies.

If you set this to False, Pants will not attempt to validate the metadata headers for your user lockfiles. This is useful so that you can keep `[python].invalid_lockfile_behavior` set to `error` or `warn` if you&#x27;d like so that tool lockfiles continue to be validated, while user lockfiles are skipped.

</Option>

### `run_against_entire_lockfile`

<Option
  cli_repr={`--[no-]python-run-against-entire-lockfile`}
  env_repr='PANTS_PYTHON_RUN_AGAINST_ENTIRE_LOCKFILE'
  default_repr={`False`}
>

If enabled, when running binaries, tests, and REPLs, Pants will use the entire lockfile file instead of just the relevant subset.

This can improve performance and reduce cache size, but has two consequences:

1. All cached test results will be invalidated if any requirement in the lockfile changes, rather than just those that depend on the changed requirement.
2. Requirements unneeded by a test/run/repl will be present on the sys.path, which might in rare cases cause their behavior to change.

This option does not affect packaging deployable artifacts, such as PEX files, wheels and cloud functions, which will still use just the exact subset of requirements needed.

</Option>

### `resolver_manylinux`

<Option
  cli_repr={`--python-resolver-manylinux=<str>`}
  env_repr='PANTS_PYTHON_RESOLVER_MANYLINUX'
  default_repr={`manylinux2014`}
>

Whether to allow resolution of manylinux wheels when resolving requirements for foreign linux platforms. The value should be a manylinux platform upper bound, e.g.: &#x27;manylinux2010&#x27;, or else the string &#x27;no&#x27; to disallow.

</Option>

### `tailor_ignore_solitary_init_files`

<Option
  cli_repr={`--[no-]python-tailor-ignore-solitary-init-files`}
  env_repr='PANTS_PYTHON_TAILOR_IGNORE_SOLITARY_INIT_FILES'
  default_repr={`True`}
>

Don&#x27;t tailor `python_sources` targets for solitary `__init__.py` files, as those usually exist as import scaffolding rather than true library code.

Set to False if you commonly have packages containing real code in `__init__.py` and there are no other .py files in the package.

</Option>

### `tailor_requirements_targets`

<Option
  cli_repr={`--[no-]python-tailor-requirements-targets`}
  env_repr='PANTS_PYTHON_TAILOR_REQUIREMENTS_TARGETS'
  default_repr={`True`}
>

Tailor python_requirements() targets for requirements files.

</Option>

### `tailor_pex_binary_targets`

<Option
  cli_repr={`--[no-]python-tailor-pex-binary-targets`}
  env_repr='PANTS_PYTHON_TAILOR_PEX_BINARY_TARGETS'
  default_repr={`True`}
>

Tailor pex_binary() targets for Python entry point files.

</Option>

## Deprecated options

### `experimental_lockfile`

<Option
  cli_repr={`--python-experimental-lockfile=<file>`}
  env_repr='PANTS_PYTHON_EXPERIMENTAL_LOCKFILE'
  default_repr={`None`}
  removal_version='2.11.0.dev0'
  removal_hint={'Instead, use the improved `[python].resolves` mechanism. Read its help message for more information.<br /><br />If you want to keep using a single resolve like before, update `[python].resolves` with a name for the resolve and the path to its lockfile, or use the default. Then make sure that `[python].default_resolve` is set to that resolve name.'}
>

Deprecated.

</Option>

### `resolver_jobs`

<Option
  cli_repr={`--python-resolver-jobs=<int>`}
  env_repr='PANTS_PYTHON_RESOLVER_JOBS'
  default_repr={`#cores/2`}
  removal_version='2.11.0.dev0'
  removal_hint={'Now set automatically based on the amount of concurrency available.'}
>

The maximum number of concurrent jobs to build wheels with.

Because Pants can run multiple subprocesses in parallel, the maximum total parallelism will be `--process-execution-{local,remote}-parallelism x --python-resolver-jobs`.

Setting this option higher may result in better parallelism, but, if set too high, may result in starvation and Out of Memory errors.

</Option>

</span>

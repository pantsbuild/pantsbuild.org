---
title: test
description: |
  Run tests.
---

import Option from "@site/src/components/reference/Option";
import styles from "@site/src/components/reference/styles.module.css";

---

```
pants test [args]
```

Run tests.

Backend: <span className="color--primary">`pants.core`</span>

Config section: <span className="color--primary">`[test]`</span>

<span className={styles.options}>

## Basic options

### `attempts_default`

<Option
  cli_repr={`--test-attempts-default=<int>`}
  env_repr='PANTS_TEST_ATTEMPTS_DEFAULT'
  toml_repr={`[test]
attempts_default = <int>`}
  default_repr={`1`}
>

The number of attempts to run tests, in case of a test failure. Tests that were retried will include the number of attempts in the summary output.

</Option>

### `debug`

<Option
  cli_repr={`--[no-]test-debug`}
  env_repr='PANTS_TEST_DEBUG'
  toml_repr={`[test]
debug = <bool>`}
  default_repr={`False`}
>

Run tests sequentially in an interactive process. This is necessary, for example, when you add breakpoints to your code.

</Option>

### `debug_adapter`

<Option
  cli_repr={`--[no-]test-debug-adapter`}
  env_repr='PANTS_TEST_DEBUG_ADAPTER'
  toml_repr={`[test]
debug_adapter = <bool>`}
  default_repr={`False`}
>

Run tests sequentially in an interactive process, using a Debug Adapter (https://microsoft.github.io/debug-adapter-protocol/) for the language if supported.

The interactive process used will be immediately blocked waiting for a client before continuing.

This option implies `--debug`.

</Option>

### `extra_env_vars`

<Option
  cli_repr={`--test-extra-env-vars="['<str>', '<str>', ...]"`}
  env_repr='PANTS_TEST_EXTRA_ENV_VARS'
  toml_repr={`[test]
extra_env_vars = [
    '<str>',
    '<str>',
    ...,
]`}
  default_repr={`[]`}
  target_field_name='test_extra_env_vars'
>

Additional environment variables to include in test processes. Entries are strings in the form `ENV_VAR=value` to use explicitly; or just `ENV_VAR` to copy the value of a variable in Pants&#x27;s own environment.

</Option>

### `force`

<Option
  cli_repr={`--[no-]test-force`}
  env_repr='PANTS_TEST_FORCE'
  toml_repr={`[test]
force = <bool>`}
  default_repr={`False`}
>

Force the tests to run, even if they could be satisfied from cache.

</Option>

### `open_coverage`

<Option
  cli_repr={`--[no-]test-open-coverage`}
  env_repr='PANTS_TEST_OPEN_COVERAGE'
  toml_repr={`[test]
open_coverage = <bool>`}
  default_repr={`False`}
>

If a coverage report file is generated, open it on the local system if the system supports this.

</Option>

### `output`

<Option
  cli_repr={`--test-output=<ShowOutput>`}
  env_repr='PANTS_TEST_OUTPUT'
  toml_repr={`[test]
output = <ShowOutput>`}
  one_of='all, failed, none'
  default_repr={`failed`}
>

Show stdout/stderr for these tests.

</Option>

### `shard`

<Option
  cli_repr={`--test-shard=<str>`}
  env_repr='PANTS_TEST_SHARD'
  toml_repr={`[test]
shard = <str>`}
  default_repr={``}
>

A shard specification of the form &#x22;k/N&#x22;, where N is a positive integer and k is a non-negative integer less than N.

If set, the request input targets will be deterministically partitioned into N disjoint subsets of roughly equal size, and only the k&#x27;th subset will be used, with all others discarded.

Useful for splitting large numbers of test files across multiple machines in CI. For example, you can run three shards with `--shard=0/3`, `--shard=1/3`, `--shard=2/3`.

Note that the shards are roughly equal in size as measured by number of files. No attempt is made to consider the size of different files, the time they have taken to run in the past, or other such sophisticated measures.

</Option>

### `timeouts`

<Option
  cli_repr={`--[no-]test-timeouts`}
  env_repr='PANTS_TEST_TIMEOUTS'
  toml_repr={`[test]
timeouts = <bool>`}
  default_repr={`True`}
>

Enable test target timeouts. If timeouts are enabled then test targets with a `timeout=` parameter set on their target will time out after the given number of seconds if not completed. If no timeout is set, then either the default timeout is used or no timeout is configured.

</Option>

### `use_coverage`

<Option
  cli_repr={`--[no-]test-use-coverage`}
  env_repr='PANTS_TEST_USE_COVERAGE'
  toml_repr={`[test]
use_coverage = <bool>`}
  default_repr={`False`}
>

Generate a coverage report if the test runner supports it.

</Option>

## Advanced options

### `batch_size`

<Option
  cli_repr={`--test-batch-size=<int>`}
  env_repr='PANTS_TEST_BATCH_SIZE'
  toml_repr={`[test]
batch_size = <int>`}
  default_repr={`128`}
>

The target maximum number of files to be included in each run of batch-enabled test runners.

Some test runners can execute tests from multiple files in a single run. Test implementations will return all tests that _can_ run together as a single group - and then this may be further divided into smaller batches, based on this option. This is done:

1. to avoid OS argument length limits (in processes which don&#x27;t support argument files)
2. to support more stable cache keys than would be possible if all files were operated on in a single batch
3. to allow for parallelism in test runners which don&#x27;t have internal parallelism, or -- if they do support internal parallelism -- to improve scheduling behavior when multiple processes are competing for cores and so internal parallelism cannot be used perfectly

In order to improve cache hit rates (see 2.), batches are created at stable boundaries, and so this value is only a &#x22;target&#x22; max batch size (rather than an exact value).

NOTE: This parameter has no effect on test runners/plugins that do not implement support for batched testing.

</Option>

### `experimental_report_test_result_info`

<Option
  cli_repr={`--[no-]test-experimental-report-test-result-info`}
  env_repr='PANTS_TEST_EXPERIMENTAL_REPORT_TEST_RESULT_INFO'
  toml_repr={`[test]
experimental_report_test_result_info = <bool>`}
  default_repr={`False`}
>

Report information about the test results.

For now, it reports only the source from where the test results were fetched. When running tests, they may be executed locally or remotely, but if there are results of previous runs available, they may be retrieved from the local or remote cache, or be memoized. Knowing where the test results come from might be useful when evaluating the efficiency of the cache and the nature of the changes in the source code that may lead to frequent cache invalidations.

</Option>

### `report`

<Option
  cli_repr={`--[no-]test-report`}
  env_repr='PANTS_TEST_REPORT'
  toml_repr={`[test]
report = <bool>`}
  default_repr={`False`}
>

Write test reports to `--report-dir`.

</Option>

### `report_dir`

<Option
  cli_repr={`--test-report-dir=<str>`}
  env_repr='PANTS_TEST_REPORT_DIR'
  toml_repr={`[test]
report_dir = <str>`}
  default_repr={`{distdir}/test/reports`}
>

Path to write test reports to. Must be relative to the build root.

</Option>

### `show_rerun_command`

<Option
  cli_repr={`--[no-]test-show-rerun-command`}
  env_repr='PANTS_TEST_SHOW_RERUN_COMMAND'
  toml_repr={`[test]
show_rerun_command = <bool>`}
  default_repr={`True`}
>

If tests fail, show an appropriate `pants test ...` invocation to rerun just those tests.

This is to make it easy to run those tests on a new machine (for instance, run tests locally if they fail in CI): caching of successful tests means that rerunning the exact same command on the same machine will already automatically only rerun the failures.

This defaults to `True` when running in CI (as determined by the `CI` environment variable being set) but `False` elsewhere.

</Option>

### `timeout_default`

<Option
  cli_repr={`--test-timeout-default=<int>`}
  env_repr='PANTS_TEST_TIMEOUT_DEFAULT'
  toml_repr={`[test]
timeout_default = <int>`}
  default_repr={`None`}
>

The default timeout (in seconds) for a test target if the `timeout` field is not set on the target.

</Option>

### `timeout_maximum`

<Option
  cli_repr={`--test-timeout-maximum=<int>`}
  env_repr='PANTS_TEST_TIMEOUT_MAXIMUM'
  toml_repr={`[test]
timeout_maximum = <int>`}
  default_repr={`None`}
>

The maximum timeout (in seconds) that may be used on a test target.

</Option>

## Deprecated options

None

## Related subsystems

- [debug-adapter](../subsystems/debug-adapter.mdx)
- [environments-preview](../subsystems/environments-preview.mdx)
- [filter](../subsystems/filter.mdx)
- [system-binaries](../subsystems/system-binaries.mdx)

</span>
